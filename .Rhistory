rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .0001, activation = 'tanh', input_shape = k) %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_sgd( lr= 0.0000001),
loss = 'mse',
metrics = c('accuracy'))
model %>% fit(X_train, Y_train, epochs = 10)
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .0001, activation = 'tanh', input_shape = k) %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_sgd( lr= 0.0000001),
loss = 'mse',
metrics = c('mse'))
model %>% fit(X_train, Y_train, epochs = 10)
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .0001, activation = 'tanh', input_shape = k) %>%
layer_dense(units = .001, activation = 'linear')
model %>% compile(optimizer = optimizer_sgd( lr= 0.0000001),
loss = 'mse',
metrics = c('mse'))
model %>% fit(X_train, Y_train, epochs = 10)
newdf <- left_join(train, properties, by='id_parcel')
newdf <- newdf %>% select(everything(), -id_parcel, -date, -zoning_property, -zoning_landuse_county)
N = nrow(newdf)
p = ncol(newdf)
X = newdf[, -1]
Y = newdf[, 1]
data = cbind(X, Y)
Ind = sample(N, N*0.75, replace = FALSE)
p = ncol(data)
Y_train = data.matrix(data[Ind, p])
X_train  = data.matrix(data[Ind, -p])
Y_test = data.matrix(data[-Ind, p])
X_test  = data.matrix(data[-Ind, -p])
k = ncol(X_train)
Y_train <- (Y_train[,1] - min(Y_train[,1])) / (max(Y_train[,1]) - min(Y_train[,1]))
model <- keras_model_sequential()
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .0001, activation = 'tanh', input_shape = k) %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_sgd( lr= 0.0000001),
loss = 'mse',
metrics = c('mse'))
model %>% fit(X_train, Y_train, epochs = 10)
rm(model())
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .0001, activation = 'tanh', input_shape = k) %>%
layer_dropout(rate=0.001)%>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_sgd( lr= 0.0000001),
loss = 'mse',
metrics = c('mse'))
model %>% fit(X_train, Y_train, epochs = 10)
loss_and_metrics <- model %>% evaluate(X_test, Y_test, batch_size = 128)
loss_and_metrics
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .0001, activation = 'tanh', input_shape = k) %>%
layer_dropout(rate=0.001)%>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = 'adam',
loss = 'mse',
metrics = c('mse'))
model %>% fit(X_train, Y_train, epochs = 10)
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .0001, activation = 'tanh', input_shape = k) %>%
layer_dropout(rate=0.001)%>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = 'adam',
loss = 'mse',
metrics = c('accuracy'))
model %>% fit(X_train, Y_train, epochs = 10)
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .0001, activation = 'tanh', input_shape = k) %>%
layer_dropout(rate=0.001)%>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = 'adam',
loss = 'mse',
metrics = c('mae'))
model %>% fit(X_train, Y_train, epochs = 10)
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .0001, activation = 'tanh', input_shape = k) %>%
layer_dropout(rate=0.001) %>%
layer_dense(units = .0001, activation = 'sigmoid') %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = 'adam',
loss = 'mse',
metrics = c('mae'))
model %>% fit(X_train, Y_train, epochs = 10)
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .0001, activation = 'tanh', input_shape = k) %>%
layer_dropout(rate=0.001) %>%
layer_dense(units = .00001, activation = 'relu') %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = 'adam',
loss = 'mse',
metrics = c('mae'))
model %>% fit(X_train, Y_train, epochs = 10)
track <- model %>% fit(X_train, Y_train, epochs = 10)
track <- model %>% fit(X_train, Y_train, epochs = 10, bath_size = 128)
track <- model %>% fit(X_train, Y_train, epochs = 10, bath_size = 10)
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .0001, activation = 'tanh', input_shape = k) %>%
layer_dropout(rate=0.001) %>%
layer_dense(units = .00001, activation = 'relu') %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = 'adam',
loss = 'mse',
metrics = c('mae'))
track <- model %>% fit(X_train, Y_train, epochs = 10, bath_size = 5)
plot(track)
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .0001, activation = 'tanh', input_shape = k) %>%
layer_dropout(rate=0.001) %>%
layer_dense(units = .00001, activation = 'relu') %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_adam(lr=0.0001),
loss = 'mse',
metrics = c('mae'))
track <- model %>% fit(X_train, Y_train, epochs = 10, bath_size = 5)
plot(track)
pred <- model %>% predict(X_test, batch_size = 5)
Y_pred = round(pred)
Y_pred
pred
Y_pred = round(pred,3)
y_pred
Y_red
Y_pred
track <- model %>% fit(X_train, Y_train, epochs = 3, bath_size = 5)
Y_pred
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .0001, activation = 'tanh', input_shape = k) %>%
layer_dense(units = .00001, activation = 'relu') %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_adam(lr=0.0001),
loss = 'mse',
metrics = c('mae'))
track <- model %>% fit(X_train, Y_train, epochs = 3, bath_size = 5)
plot(track)
pred <- model %>% predict(X_test, batch_size = 128)
pred
X_test
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .0001, activation = 'tanh', input_shape = k) %>%
layer_dense(units = .00001, activation = 'relu') %>%
layer_dense(units = 1, activation = 'rmsprop')
model %>%
layer_dense(units = .0001, activation = 'tanh', input_shape = k) %>%
layer_dense(units = .00001, activation = 'relu') %>%
layer_dense(units = 1, activation = 'tanh')
model %>% compile(optimizer = optimizer_adam(lr=0.0001),
loss = 'mse',
metrics = c('mae'))
track <- model %>% fit(X_train, Y_train, epochs = 3, bath_size = 5)
plot(track)
pred <- model %>% predict(X_test, batch_size = 128)
Y_pred = round(pred)
pred
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .0001, activation = 'tanh', input_shape = k) %>%
layer_dense(units = .00001, activation = 'sigmoid') %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_adam(lr=0.0001),
loss = 'mse',
metrics = c('mae'))
track <- model %>% fit(X_train, Y_train, epochs = 70, bath_size = 5)
track <- model %>% fit(X_train, Y_train, epochs = 70, bath_size = 5)
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .0001, activation = 'tanh', input_shape = k) %>%
layer_dense(units = .00001, activation = 'sigmoid') %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_adam(lr=0.0001),
loss = 'mse',
metrics = c('mae'))
track <- model %>% fit(X_train, Y_train, epochs = 70, bath_size = 5)
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .0001, activation = 'tanh', input_shape = k) %>%
layer_dense(units = .00001, activation = 'sigmoid') %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_adam(lr=0.00001),
loss = 'mse',
metrics = c('mae'))
track <- model %>% fit(X_train, Y_train, epochs = 70, bath_size = 5)
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .0001, activation = 'tanh', input_shape = k) %>%
layer_dense(units = .00001, activation = 'sigmoid') %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_adam(lr=0.00001),
loss = 'mse',
metrics = c('mae'))
track <- model %>% fit(X_train, Y_train, epochs = 15, bath_size = 5)
pred <- model %>% predict(X_test, batch_size = 5)
Y_pred
pred
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .00001, activation = 'tanh', input_shape = k) %>%
layer_dense(units = .00001, activation = 'sigmoid') %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_adam(lr=0.00001),
loss = 'mse',
metrics = c('mae'))
track <- model %>% fit(X_train, Y_train, epochs = 15, bath_size = 5)
rm(pred)
pred <- model %>% predict(X_test, batch_size = 5)
pred
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .00001, activation = 'tanh', input_shape = k) %>%
layer_dense(units = .00001, activation = 'sigmoid') %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_adam(lr=0.00001),
loss = 'mse',
metrics = c('mae', 'accuracy', 'training error'))
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .00001, activation = 'tanh', input_shape = k) %>%
layer_dense(units = .00001, activation = 'sigmoid') %>%
layer_dense(units = 1, activation = 'linear')
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .000001, activation = 'tanh', input_shape = k) %>%
layer_dense(units = .000001, activation = 'sigmoid') %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_adam(lr=0.000001),
loss = 'mse',
metrics = c('mae', 'accuracy'))
track <- model %>% fit(X_train, Y_train, epochs = 15, bath_size = 5)
rm(pred)
pred <- model %>% predict(X_test, batch_size = 5)
pred
?layer_dense
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .000001, activation = 'tanh', input_shape = k) %>%
layer_dense(units = .000001, activation = 'sigmoid') %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_adam(lr=0.00001),
loss = 'mse',
metrics = c('mae', 'accuracy'))
track <- model %>% fit(X_train, Y_train, epochs = 15, bath_size = 64)
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .000001, activation = 'tanh', input_shape = k) %>%
layer_dense(units = .000001, activation = 'sigmoid') %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_adam(lr=0.00001),
loss = 'mse',
metrics = c('mae', 'accuracy'))
track <- model %>% fit(X_train, Y_train, epochs = 100, bath_size = 64)
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .000001, activation = 'tanh', input_shape = k) %>%
layer_dense(units = .000001, activation = 'sigmoid') %>%
layer_dense(units = 1, activation = 'relu')
model %>% compile(optimizer = optimizer_adam(lr=0.00001),
loss = 'mse',
metrics = c('mae', 'accuracy'))
track <- model %>% fit(X_train, Y_train, epochs = 50, bath_size = 64)
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .000001, activation = 'relu', input_shape = k) %>%
layer_dense(units = .000001, activation = 'sigmoid') %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_adam(lr=0.00001),
loss = 'mse',
metrics = c('mae', 'accuracy'))
track <- model %>% fit(X_train, Y_train, epochs = 50, bath_size = 64)
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .000001, activation = 'relu', input_shape = k) %>%
layer_dense(units = .000001, activation = 'relu') %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_adam(lr=0.00001),
loss = 'mse',
metrics = c('mae', 'accuracy'))
track <- model %>% fit(X_train, Y_train, epochs = 50, bath_size = 64)
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .000001, activation = 'relu', input_shape = k) %>%
layer_dense(units = .000001, activation = 'relu') %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_rmsprop(lr=0.00001),
loss = 'mse',
metrics = c('mae', 'accuracy'))
track <- model %>% fit(X_train, Y_train, epochs = 50, bath_size = 64)
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .000001, activation = 'relu', input_shape = k) %>%
layer_dense(units = .000001, activation = 'relu') %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_sgd(lr=0.00001),
loss = 'mse',
metrics = c('mae', 'accuracy'))
track <- model %>% fit(X_train, Y_train, epochs = 50, bath_size = 64)
rm(model)
model %>%
layer_dense(units = .000001, activation = 'relu', input_shape = k) %>%
layer_dense(units = .000001, activation = 'relu') %>%
layer_dense(units = 1, activation = 'tanh')
rm(model)
model <- keras_model_sequential()
model %>%
layer_dense(units = .000001, activation = 'tanh', input_shape = k) %>%
layer_dense(units = .000001, activation = 'relu') %>%
layer_dense(units = 1, activation = 'linear')
model %>% compile(optimizer = optimizer_sgd(lr=0.00001),
loss = 'mse',
metrics = c('mae', 'accuracy'))
track <- model %>% fit(X_train, Y_train, epochs = 50, bath_size = 64)
library(dplyr)
cars_cyl <- mtcars
mtcars
rm(df, cars_cyl)
library(googleComputeEngineR)
project <- "my-project-1491496166180"
zone <- "us-west1-b"
account_key <- "~/gcsdemo/gcs-key.json"
Sys.setenv(GCE_AUTH_FILE = account_key,
GCE_DEFAULT_PROJECT_ID = project,
GCE_DEFAULT_ZONE = zone)
gce_auth()
gce_global_project(project)
gce_global_zone(zone)
default_project<- gce_get_project("my-project-1491496166180")
default_project$name
tag <- gce_tag_container("hadleyverse-crontab", project = "gcer-public")
vm2 <- gce_vm("rstudio-cron",
predefined_type = "n1-highmem-2",
template = "rstudio",
dynamic_image = tag,
username = "mcarrie30",
password = "blah123",
disk_size_gb = 30)
vm2 <- gce_vm("rstudio-cron",
predefined_type = "n1-highmem-2",
template = "rstudio",
dynamic_image = tag,
username = "mcarrie30",
password = "blah123",
disk_size_gb = "30")
?gce_vm
vm2 <- gce_vm("rstudio-cron",
predefined_type = "n1-highmem-2",
template = "rstudio",
dynamic_image = tag,
username = "mcarrie30",
password = "blah123")
job <- gce_vm_stop("rstudio-cron")
job <- gce_vm_start("rstudio-cron")
library(googleComputeEngineR)
project <- "my-project-1491496166180"
zone <- "us-west1-b"
account_key <- "~/gcsdemo/gcs-key.json"
Sys.setenv(GCE_AUTH_FILE = account_key,
GCE_DEFAULT_PROJECT_ID = project,
GCE_DEFAULT_ZONE = zone)
gce_auth()
gce_global_project(project)
gce_global_zone(zone)
default_project<- gce_get_project("my-project-1491496166180")
default_project$name
tag <- gce_tag_container("hadleyverse-crontab", project = "gcer-public")
vm2 <- gce_vm("rstudio-cron",
predefined_type = "n1-highmem-2",
template = "rstudio",
dynamic_image = tag,
username = "mcarrie30",
password = "blah123")
install.packages("UpSetR")
movies <- read.csv( system.file("extdata", "movies.csv", package = "UpSetR"), header=T, sep=";" )
mutations <- read.csv( system.file("extdata", "mutations.csv", package = "UpSetR"), header=T, sep = ",")
upset(movies,attribute.plots=list(gridrows=60,plots=list(list(plot=scatter_plot, x="ReleaseDate", y="AvgRating"),
))
)))
upset(movies,attribute.plots=list(gridrows=60,plots=list(list(plot=scatter_plot, x="ReleaseDate", y="AvgRating"),
list(plot=scatter_plot, x="ReleaseDate", y="Watches"),list(plot=scatter_plot, x="Watches", y="AvgRating"),
list(plot=histogram, x="ReleaseDate")), ncols = 2))
library(UpSetR)
upset(movies,attribute.plots=list(gridrows=60,plots=list(list(plot=scatter_plot, x="ReleaseDate", y="AvgRating"),
list(plot=scatter_plot, x="ReleaseDate", y="Watches"),list(plot=scatter_plot, x="Watches", y="AvgRating"),
list(plot=histogram, x="ReleaseDate")), ncols = 2))
View(df)
library(flexdashboard)
df <- read.csv("6085500_flow-orders_58CAE62A027F0030011901F3.qGDp8E.csv",sep = ",", header=T,na.strings=c("","NA"))
View(df)
upset(df,attribute.plots=list(gridrows=60,plots=list(list(plot=scatter_plot, x="order_date", y="filled_quantity")
list(plot=scatter_plot, x="ReleaseDate", y="Watches"),list(plot=scatter_plot, x="Watches", y="AvgRating"),
list(plot=histogram, x="ReleaseDate")), ncols = 2))
upset(df,attribute.plots=list(gridrows=60,plots=list(list(plot=scatter_plot, x="order_date", y="filled_quantity"))))
View(movies)
View(mutations)
library(keras)
library(keras)
library(readxl)
library(caret)
library(caret)
library(tidyverse)
sample <- read.csv('sample_submission.csv')
sample <- read.csv('sample_submission.csv')
train <- read.csv('train_2016_v2.csv')
properties <- read.csv('properties_2016.csv')
library(keras)
model <- keras_model_sequential()
model %>%
layer_dense(units = 512, activation = 'relu', input_shape = c(784)) %>%
layer_dropout(rate = 0.2) %>%
layer_dense(units = 512, activation = 'relu') %>%
layer_dropout(rate = 0.2) %>%
layer_dense(units = 10, activation = 'softmax')
model %>% compile(
loss = 'categorical_crossentropy',
optimizer = optimizer_sgd(lr = 0.02),
metrics = c('accuracy')
)
history <- model %>% fit(
x_train, y_train,
epochs = 20, batch_size = 128,
validation_split = 0.2
)
library(keras)
batch_size <- 32
epochs <- 200
data_augmentation <- TRUE
cifar10 <- dataset_cifar10()
x_train <- cifar10$train$x/255
x_test <- cifar10$test$x/255
y_train <- to_categorical(cifar10$train$y, num_classes = 10)
y_test <- to_categorical(cifar10$test$y, num_classes = 10)
x_train <- cifar10$train$x/255
x_train
x_train <- cifar10$train$x/255
x_test <- cifar10$test$x/255
y_train <- to_categorical(cifar10$train$y, num_classes = 10)
y_test <- to_categorical(cifar10$test$y, num_classes = 10)
cifar10
head(cifar10)
y_train
library(dplyr)
rm(df)
rm(path)
install.packages("rvest")
library("rvest", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
detach("package:rvest", unload=TRUE)
library(tidyverse)
library(quantmod)
detach("package:quantmod", unload=TRUE)
library(tidyquant)
library(keras)
setwd("~/GITHUB/Dsblog/")
library(blogdown)
serve_site()
library(plotly)
knitr::opts_chunk$set(collapse = TRUE)
summary(cars)
cars
cars
plot_ly(cars, x=~speed, y=~distance, type='scatter')
cars
plot_ly(cars, x=~speed, y=~dist, type='scatter')
serve_site()
serve_site()
plot_ly(cars, x=~speed, y=~dist, type='markers')
plot_ly(cars, x=~speed, y=~dist, type='scatter')
serve_site()
